% Chapter Template

\chapter{Results} % Main chapter title

\label{Chapter7} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}


After comparing both the existing Project EPIC infrastructure and my system prototype, I am now going to reflect on possible answers to the questions proposed in \autoref{Chapter3}.

My work suggests that Project EPIC should invest the effort to migrate its existing infrastructure to the new software architecture enabled by container-orchestration systems. While my prototype does not recreate all of the functionality of EPIC Collect and EPIC Analyze, I have been able to reconstruct the core aspects of these systems in approximately one semester of effort, using less code, and exceeding the existing infrastructure in terms of scalabilty, reliability, ease of configuration and deployment, and maintainability---all because of the benefits provided by containerization, container-orchestration systems, and microservices.

Kubernetes provides many features that makes my prototype more scalable and reliable. Rather than having to rely on ad hoc monitoring approaches, system monitoring is built into Kubernetes and provides for a wide range of features: replicas, rolling updates, auto-scaling, etc. None of those features are available in the current Project EPIC infrastructure and would require significant refactoring to add. Furthermore, my approach to using stateless microservices provides me with flexiblity and scalability that Project EPIC's current infrastructure cannot match. Lastly, by making use of Google Cloud, I am able to create clusters with a flexiblity that just is not possible with Project EPIC's fixed set of machines in a traditional data center.

Regarding mantainability, my prototype has several advantages. First, my use of microservices separates responsabilities into different components that are smaller in size than the stateful components found in the existing infrastructure. This size difference makes it easier for developers to engage in the maintenance of individual microservices without having to understand the whole system at once. This design, in turn, means that we do not need experts for the whole system; each microservice can be mantained independently. In addition, Kubernetes offers a platform to deploy microservices that provides a better separation between deployment infrastructure and application development. Developers do not need a system administrator to deploy their code; they just need to understand how containerization works. Once they have wrapped their microservice into a container, it can easily be deployed and plugged into all of the reliablity and scalability features that Kubernetes provides. Furthermore, Kubernetes is a platform that allows developers to build their own tools on top of it. Thanks to its open source community, some tools are already built and can be added into existing Kubernetes clusters with ease. For example, with respect to reliability, we can add monitoring tools into Kubernetes clusters in a straightforward way. The API exposes resource usage information allowing one to configure alerts if needed and the community has built packages of configuration files that help to deploy monitoring solutions with ease.

With respect to deployment, Kubernetes's configuration files make it straightforward to specify the configuration of extensible, microservice-based software systems. With these configuration files, it makes it possible to migrate systems from one cloud provider to another, providing a means for saving on infrastructure costs. The Kubernetes scheduler then attempts to deploy the specified software system in the most optimal way, making best efforts to instantiate the described system within the constraints of the resources available on the cluster. Adding nodes to an existing cluster, then provides Kubernetes with the capacity it needs to allow a system to scale and become more reliable.

Finally, Kubernetes makes it possible to upgrade a software system easily. Each microservice can be independently upgraded using the rolling update withough having to upgrade the whole system at once and new components can be easily added due to the use of a message broker. You can first add a new service that generates a new type of message. You can then add services that will process those messages and then wire those services together by connecting up the message queues.

Given all of these benefits, my thesis work has shown that it is time for a major migration of the Project EPIC infastructure to the new approach represented by container-orchestration systems. Such a migration can build off the work I have invested in creating my system prototype, identifying new microservices that need to be added to further extend the overall functionality of the system and bring it closer to the full extent of services offered by the existing infrastructure.
