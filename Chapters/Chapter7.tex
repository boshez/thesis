% Chapter Template

\chapter{Results} % Main chapter title

\label{Chapter7} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}


After analyzing and comparing both system we are going to extract and do a definitive comparison to answer the proposed questions in \autoref{Chapter3}.

On the advantadges/limitation respect our current system, we have see some new capabilities for the system that were too complex to implement in the previous infrastructure of Project EPIC. One of them is the system availability tracking. Moving it to an external tooling allows us to ignore how it will be deployed while developing and focus more on the code and performance of each component. This makes the system more reliable at the same time that keep development simplicity. However the field that seems to have a major improvement is scalability. Thanks to the stateless microservice approach, scaling is easier than before. In addition, the container orchestration systems provides an abstraction layer to scale up and down different components individually saving us time for configuration. Resource intensive workload can be more efficient by scaling up the resource intensive instances, increasing the throughput if the system needs it. 

Regarding mantainability costs, we have several improvements. First, using microservices, separates responsabilities into different components that are smaller in size. This size difference makes it easier for developers to embark into each microservice mantainance without having to understand the whole system at once. This in turn means that we don't need experts for the whole system, each microservice can be mantainer independently. On the other side, Kubernetes offers a platform to deploy the microservices that allows a better separation between deployment infrastrustructure and application development. Developers donâ€™t need a system administrator or a system expert to deploy their code, they just need to understand how containerization works. The rest can be done easily. It also allows for specific tooling to be developed. Kubernetes is like a system platform, where you can create your own tooling. Thanks to the community, some tools are already built, and can be added with ease into Kubernetes clusters. As an example for reliability, we can add monitoring tools into Kubernetes clusters in a really easy way. The API exposes resource usage allowing you to configure alerts if needed, and the community has built packages of configuration files that help to deploy monitoring with ease.

About deploying the infrastructure, we can create configuration files that can be used in the container orchestrated system. Making it really easy and fast to deploy into any Kubernetes cluster. This makes it easier to migrate between different cloud providers allowing to focus on saving infrastructure costs. Another aspect that lower the mantainence cost is the Kubernetes scheduler. Thanks to its dynamic instance assignation, it allows for a better resource usage making sure we use our available resources the best as possible. In addition, as each microservice is kept small, there's a chance to do a faster development and deployment system.

We can also upgrade the system easily. Each microservice can be independently upgraded using the rolling update feature from Kubernetes. In this part we also get benefit from the microservice architecture, as we can update each microservice independently allowing for a faster upgrade time compared to upgrading the whole system at once. On the other side, the system can also be expanded easily thanks to the coreography approach. Making it also good to upgrade between technologies or on major releases updates.

